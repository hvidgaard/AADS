\section*{Comparison with priority queues}
\subsection*{The vEB tree as a priority queue}
The vEB tree can be used as a priority queue if we build some extra logic on top of it. Firstly a priority queue can contain several elements with the same priority, a search tree does not allow this. To get around this limitation we've build a new priority queue that can use any search tree as the underlying data structure. Ignoring intialization (this is just initializing the underlying search tree), we focus on the actual usage. Our priority queue support the following operations:

\begin{itemize}
  \item $void \textbf{ veb\_pq\_insert}(veb\_pq\_node * n, vebtree * tree)$
  \item $void \textbf{ veb\_pq\_delete}(vebtree * tree, veb\_pq\_node * node)$
  \item $veb\_pq\_node * \textbf{ veb\_pq\_deletemin}(vebtree * tree)$
  \item $void \textbf{ veb\_pq\_decrease\_key}(vebtree * tree, veb\_pq\_node * node, uint32\_t delta)$
\end{itemize}
A \textbf{veb\_pq\_data} is just a simple structure that contain a pointer to the first \textbf{veb\_pq\_node} in a linked list of nodes, and a counter, $n$ that is the number of nodes in the linked list. A \textbf{veb\_pq\_node} contains a pointer to the next and previous nodes, if any, and a pointer to the \textbf{veb\_pq\_data} holding the node; in particular, this last pointer allows us to check if a node is in the search tree or not, by seeing if the pointer is $NULL$. It also have an unsigned integer field that is the priority. Any auxilary data should also be included in this node - we just have a node number to indicate which node in the graph for our dijkstras algorithm it represent.

\begin{pseudocode}[Ovalbox]{veb\_pq\_insert}{node, tree}
data \GETS \text{succesor}(node.prio, tree)\\
\IF data.prio = node.prio
\THEN \text{insert $n$ into the linked list in $data$}
\ELSE 
\BEGIN
data \GETS \text{new veb\_pq\_data with a single element, $node$} \\
  \text{insert}(data, tree)
\END
\end{pseudocode}

Let $T_{succ}(n)$ be the time for finding the successor to $n$, in the underlying datastructure, and let $T_{insert}(n)$ be the time to insert an element. Inserting $n$ into the linked list is a matter of updating a few, but constant number of pointers, so $O(1)$. The total time it takes to insert an element is $O(T_{succ}(n) + T_{insert}(n)$. With vEB trees as the underlying data structure, it's $O(\log \log U)$.

\begin{pseudocode}[Ovalbox]{veb\_pq\_delete}{node, tree}
\IF node.parent.n > 1
\THEN \text{then remove $node$ from the linked list}
\ELSE \text{remove}(node.parent, tree)
\end{pseudocode}

It is assumed we have a pointer to the node we want to delete. If the parent to the node have more than one element, it's a matter of updating a few pointers, but by the same argument as for \textbf{veb\_pq\_insert}, the time is $O(T_{remove}(n))$ which translates to $O(\log \log U)$, in the worst case where the node is the only node in the parent..

\subsubsection*{\textbf{veb\_pq\_deletemin}}
Since vEB trees have a pointer to the minimum element, this can be fetched in constant time. The running time of \textbf{veb\_pq\_deletemin} is therefore $O(T_{remove}(n)) = O(\log \log U)$. The observant reader will notice that this means we can sort the integers $0, \dots, U$ in time $O(k \cdot \log \log U)$, where $k$ is the number of integers. So have we broken the $O(n \cdot \log n)$ barrier for comparison based integer sorting? No. In order to sort an arbitraty range of integers, we firstly need to build the vEB tree. Since this has size $O(U) = O(2^m)$, it takes $O(2^m)$ to build, where m is the bit length used for the vEB tree. This is clearly at least as large as $O(n)$. But for any fixed size integers set, we can sort efficiently by reusing the same vEB data structure.

\begin{pseudocode}[Ovalbox]{veb\_pq\_decreasekey}{node, delta, tree}
\text{veb\_pq\_delete}(node, tree)\\
node.prio \GETS n.prio - delta\\
\text{veb\_pq\_insert}(node, tree)
\end{pseudocode}

With a running time of $O(O(\log \log U) + O(\log \log U)) = O(\log \log U)$.

All operations on our priority queue with vEB takes $O(\log \log U)$ time, except initialization.

\subsection*{Benchmarking}
From the previous project, we had a graph generating algorithm that would generate a large number of decrease calls, such that the binary heap would do $\log n$ work, i.e bubble the element, a leaf, all the way to the root. The Fibonacci heaps have the obvious advantage that they have amotized $O(1)$ time for decrease key calls, and vEB have $O(\log \log n)$. Question is, is the hidden constants too large for practical purposes?

\subsubsection*{Dijkstra: dkmax2 graph}
\begin{figure}[htb]
\centering
\includegraphics[width=0.8\textwidth]{../benchmark/cli/dkmax2_dk.png}
\caption{Decrease key average}
\label{fig:dkmax2-dk}
\end{figure}

It's obvious to see here, that both Fibonacci Heap and vEB trees have constant time for the decrease key operation. For Fibonacci heap this is expected, and the vEB it is because we don't change the size of the universe. We could make the size of the universe just large enough to fit all the data, and this is expected to show a $\log \log U$ growing function. However, since it we only decrease the depth by 1, when we half the bitlenght of the input, it's expected to jump in intervals, rather than being a nice growing graph.

\begin{figure}[htb]
\centering
\includegraphics[width=0.8\textwidth]{../benchmark/cli/dkmax2_dm.png}
\caption{Deletemin average}
\label{fig:dkmax2-dm}
\end{figure}

Here it's painfully obvious that our Fibonacci Heap delete min operation is done wrong.

\begin{figure}[htb]
\centering
\includegraphics[width=0.8\textwidth]{../benchmark/cli/dkmax2_ins.png}
\caption{Insert average}
\label{fig:dkmax2-ins}
\end{figure}

The insert average is constant, which for Fibonacci Heap and vEB is expected, one due to the amotized $O(1)$ insert, and the other because the size of the universe is constant. For the Binary Heap, it is because it always inserts an element at the very end, and the algorithm insert elements with the maximum priority the first time, it doesn't have to bubble it up. It does not insert elements beyond this.

\begin{figure}[htb]
\centering
\includegraphics[width=0.8\textwidth]{../benchmark/cli/dkmax2_total.png}
\caption{Total running time}
\label{fig:dkmax2-tot}
\end{figure}

When looking at the total running time, vEB tree does not look so good. If we had implemented Fibonacci Heaps correctly, it would be even faster, but it would still have a $O(\log n)$ delete minimum operation, and theoretically, for large enough inputs it should become slower than vEB at some point, because for both data structures the other operations are constant on average. But since we cannot have large enough vEB structures in the ram, we cannot benchmark beyond $n=4000$ because we use $n^2$ as the priority of one node for our graph, and that is very close to the maximum for the vEB tree when using 24-bits for the index.
